{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.eager as tfe\n",
    "import numpy as np\n",
    "import math\n",
    "import timeit\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.misc\n",
    "import pickle\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cifar10(num_training=49000, num_validation=1000, num_test=10000):\n",
    "    \"\"\"\n",
    "    Fetch the CIFAR-10 dataset from the web and perform preprocessing to prepare\n",
    "    it for the two-layer neural net classifier. These are the same steps as\n",
    "    we used for the SVM, but condensed to a single function.\n",
    "    \"\"\"\n",
    "    # Load the raw CIFAR-10 dataset and use appropriate data types and shapes\n",
    "    cifar10 = tf.keras.datasets.cifar10.load_data()\n",
    "    (X_train, y_train), (X_test, y_test) = cifar10\n",
    "    X_train = np.asarray(X_train, dtype=np.float32)\n",
    "    y_train = np.asarray(y_train, dtype=np.int32).flatten()\n",
    "    X_test = np.asarray(X_test, dtype=np.float32)\n",
    "    y_test = np.asarray(y_test, dtype=np.int32).flatten()\n",
    "\n",
    "    # Subsample the data\n",
    "    mask = range(num_training, num_training + num_validation)\n",
    "    X_val = X_train[mask]\n",
    "    y_val = y_train[mask]\n",
    "    mask = range(num_training)\n",
    "    X_train = X_train[mask]\n",
    "    y_train = y_train[mask]\n",
    "    mask = range(num_test)\n",
    "    X_test = X_test[mask]\n",
    "    y_test = y_test[mask]\n",
    "\n",
    "    # Normalize the data: subtract the mean pixel and divide by std\n",
    "    mean_pixel = X_train.mean(axis=(0, 1, 2), keepdims=True)\n",
    "    std_pixel = X_train.std(axis=(0, 1, 2), keepdims=True)\n",
    "    X_train = (X_train - mean_pixel) / std_pixel\n",
    "    X_val = (X_val - mean_pixel) / std_pixel\n",
    "    X_test = (X_test - mean_pixel) / std_pixel\n",
    "\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test\n",
    "\n",
    "\n",
    "# Invoke the above function to get our data.\n",
    "NHW = (0, 1, 2)\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = load_cifar10()\n",
    "print('Train data shape: ', X_train.shape)\n",
    "print('Train labels shape: ', y_train.shape, y_train.dtype)\n",
    "print('Validation data shape: ', X_val.shape)\n",
    "print('Validation labels shape: ', y_val.shape)\n",
    "print('Test data shape: ', X_test.shape)\n",
    "print('Test labels shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_datasets(X):\n",
    "    X_new = []\n",
    "    for i in range(X.shape[0]):\n",
    "        if(i % 100 == 0):\n",
    "            print(i)\n",
    "        img = scipy.ndimage.interpolation.zoom(X[i], (8.0, 8.0, 1.0))\n",
    "        X_new.append(img)\n",
    "    X_new = np.asarray(X_new, dtype=np.float32)\n",
    "    return X_new.reshape([X.shape[0], 256, 256, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Resizing Validation...')\n",
    "X_val = resize_datasets(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Resizing Test...')\n",
    "X_test = resize_datasets(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('Resizing Training...')\n",
    "X_train = resize_datasets(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_out = open(\"train_dataset.pickle\",\"wb\")\n",
    "pickle.dump(X_test, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_in = open(\"validation_dataset.pickle\",\"rb\")\n",
    "X_val = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle_in = open(\"dataset.pickle\",\"rb\")\n",
    "X_train = pickle.load(pickle_in)\n",
    "y_train = pickle.load(pickle_in)\n",
    "X_test = pickle.load(pickle_in)\n",
    "y_test = pickle.load(pickle_in)\n",
    "X_val = pickle.load(pickle_in)\n",
    "y_val = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test[:30] = X_train[:30]\n",
    "y_test[:30] = y_train[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set_size = 200\n",
    "test_set_size = 100\n",
    "valid_set_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(object):\n",
    "    def __init__(self, X, y, batch_size, shuffle=False):\n",
    "        \"\"\"\n",
    "        Construct a Dataset object to iterate over data X and labels y\n",
    "        \n",
    "        Inputs:\n",
    "        - X: Numpy array of data, of any shape\n",
    "        - y: Numpy array of labels, of any shape but with y.shape[0] == X.shape[0]\n",
    "        - batch_size: Integer giving number of elements per minibatch\n",
    "        - shuffle: (optional) Boolean, whether to shuffle the data on each epoch\n",
    "        \"\"\"\n",
    "        assert X.shape[0] == y.shape[0], 'Got different numbers of data and labels'\n",
    "        self.X, self.y = X, y\n",
    "        self.batch_size, self.shuffle = batch_size, shuffle\n",
    "\n",
    "    def __iter__(self):\n",
    "        N, B = self.X.shape[0], self.batch_size\n",
    "        idxs = np.arange(N)\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(idxs)\n",
    "        return iter((self.X[i:i+B], self.y[i:i+B]) for i in range(0, N, B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(x):\n",
    "    \"\"\"    \n",
    "    Input:\n",
    "    - TensorFlow Tensor of shape (N, D1, ..., DM)\n",
    "    \n",
    "    Output:\n",
    "    - TensorFlow Tensor of shape (N, D1 * ... * DM)\n",
    "    \"\"\"\n",
    "    N = tf.shape(x)[0]\n",
    "    return tf.reshape(x, (N, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = tf.get_variable(name = 'input', shape=[1,256,256,3], dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#globals used in the assignment\n",
    "IMG_SHAPE = [256, 256, 3] # height, width, channels\n",
    "NUM_CLASSES = 10\n",
    "\n",
    "# training hyperparameters\n",
    "LEARNING_RATE = 1e-4\n",
    "MOMENTUM = 0.9\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 30\n",
    "DISPLAY_STEP = 1\n",
    "VALIDATION_STEP = 1000\n",
    "SAVE_STEP = 1000\n",
    "CKPT_PATH = './ckpt'\n",
    "SUMMARY_PATH = './summary'\n",
    "\n",
    "# net architecture hyperparamaters\n",
    "LAMBDA = 5e-4 #for weight decay\n",
    "DROPOUT = 0.5\n",
    "\n",
    "# test hyper parameters\n",
    "K_PATCHES = 5\n",
    "TOP_K = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_compatibility(atten1_output, g):\n",
    "#     print(\"\\nCompatibility ->\")\n",
    "#     print(\"Attention : \" + str(atten1_output.numpy().shape)) #(batch, 225, 512)\n",
    "#     print(\"G : \" + str(g.numpy().shape)) #(batch, 512, 1)\n",
    "    g_new = tf.reshape(g, (g.shape[0], g.shape[2], g.shape[1])) #(batch, 1, 512)\n",
    "#     print(\"After reshaping, G : \" + str(g_new.numpy().shape))\n",
    "    g_new = tf.tile(g_new, [1, atten1_output.shape[1], 1]) #(batch, 225, 512)\n",
    "    final_vec = (g_new + atten1_output)\n",
    "#     print(\"After addition of G and L_i : \" + str(final_vec.numpy().shape))\n",
    "    return final_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlexNet(tfe.Network):\n",
    "    def __init__(self, training):\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.training = training\n",
    "        \n",
    "        # convolutional layers\n",
    "        conv_init = tf.contrib.layers.xavier_initializer_conv2d()\n",
    "        \n",
    "        self.conv1 = self.track_layer(\n",
    "            tf.layers.Conv2D(\n",
    "                96,\n",
    "                11,\n",
    "                4,\n",
    "                'SAME',\n",
    "                activation=tf.nn.relu,\n",
    "                kernel_initializer=conv_init))\n",
    "        self.pool1 = self.track_layer(tf.layers.MaxPooling2D(3, 2, 'VALID'))\n",
    "\n",
    "        self.conv2 = self.track_layer(\n",
    "            tf.layers.Conv2D(\n",
    "                256,\n",
    "                5,\n",
    "                1,\n",
    "                'SAME',\n",
    "                activation=tf.nn.relu,\n",
    "                kernel_initializer=conv_init))\n",
    "        self.pool2 = self.track_layer(tf.layers.MaxPooling2D(3, 2, 'VALID'))\n",
    "\n",
    "        self.conv3 = self.track_layer(\n",
    "            tf.layers.Conv2D(\n",
    "                384,\n",
    "                3,\n",
    "                1,\n",
    "                'SAME',\n",
    "                activation=tf.nn.relu,\n",
    "                kernel_initializer=conv_init))\n",
    "\n",
    "        self.conv4 = self.track_layer(\n",
    "            tf.layers.Conv2D(\n",
    "                384,\n",
    "                3,\n",
    "                1,\n",
    "                'SAME',\n",
    "                activation=tf.nn.relu,\n",
    "                kernel_initializer=conv_init))\n",
    "\n",
    "        self.conv5 = self.track_layer(\n",
    "            tf.layers.Conv2D(\n",
    "                256,\n",
    "                3,\n",
    "                1,\n",
    "                'SAME',\n",
    "                activation=tf.nn.relu,\n",
    "                kernel_initializer=conv_init))\n",
    "        self.pool5 = self.track_layer(tf.layers.MaxPooling2D(3, 2, 'VALID'))\n",
    "\n",
    "        # fully connected layers\n",
    "\n",
    "        fc_init = tf.contrib.layers.xavier_initializer()\n",
    "\n",
    "        self.fc1 = self.track_layer(\n",
    "            tf.layers.Dense(\n",
    "                512, kernel_initializer=fc_init))\n",
    "        self.drop1 = self.track_layer(tf.layers.Dropout(DROPOUT))\n",
    "        \n",
    "        #perceptron\n",
    "        self.perceptron1 = self.track_layer(\n",
    "            tf.layers.Dense(\n",
    "                1, kernel_initializer=fc_init))\n",
    "        \n",
    "        self.perceptron2 = self.track_layer(\n",
    "            tf.layers.Dense(\n",
    "                1, kernel_initializer=fc_init))\n",
    "        \n",
    "        #attention estimators\n",
    "        self.atten1_fc = self.track_layer(\n",
    "            tf.layers.Dense(\n",
    "                512, kernel_initializer=fc_init))\n",
    "        \n",
    "        self.atten2_fc = self.track_layer(\n",
    "            tf.layers.Dense(\n",
    "                512, kernel_initializer=fc_init))\n",
    "        \n",
    "        self.out = self.track_layer(\n",
    "            tf.layers.Dense(NUM_CLASSES, kernel_initializer=fc_init))\n",
    "\n",
    "    def call(self, x):\n",
    "        \"\"\" Function that executes the model \"\"\"\n",
    "        output = self.conv1(x)\n",
    "        #print(\"After conv1 : \" + str(output.numpy().shape))\n",
    "        output = tf.nn.lrn(\n",
    "            output, depth_radius=2, bias=1.0, alpha=2e-05, beta=0.75)\n",
    "        #print(\"After normalisation1 : \" + str(output.numpy().shape))\n",
    "        output = self.pool1(output)\n",
    "        #print(\"After pool1 : \" + str(output.numpy().shape))\n",
    "\n",
    "        output = self.conv2(output)\n",
    "        #print(\"After conv2 : \" + str(output.numpy().shape))\n",
    "        output = tf.nn.lrn(\n",
    "            output, depth_radius=2, bias=1.0, alpha=2e-05, beta=0.75)\n",
    "        #print(\"After normalisation2 : \" + str(output.numpy().shape))\n",
    "        output = self.pool2(output)\n",
    "        #print(\"After pool2 : \" + str(output.numpy().shape))\n",
    "\n",
    "        output = self.conv3(output)\n",
    "        #print(\"After conv3 : \" + str(output.numpy().shape))\n",
    "\n",
    "        output = self.conv4(output)\n",
    "        #print(\"After conv4 : \" + str(output.numpy().shape))\n",
    "        conv4_output = output\n",
    "\n",
    "        output = self.conv5(output)\n",
    "        #print(\"After conv5 : \" + str(output.numpy().shape))\n",
    "        conv5_output = output\n",
    "        \n",
    "        output = self.pool5(output)\n",
    "        #print(\"After pool5 : \" + str(output.numpy().shape))\n",
    "\n",
    "        output = tf.layers.flatten(output)\n",
    "        #print(\"After flattening : \" + str(output.numpy().shape))\n",
    "\n",
    "        output = self.fc1(output)\n",
    "        #print(\"After fc1 : \" + str(output.numpy().shape))\n",
    "        if self.training:\n",
    "            output = self.drop1(output)\n",
    "            #print(\"After drop1 : \" + str(output.numpy().shape))\n",
    "        \n",
    "        #logic for attention estimators\n",
    "        g = tf.reshape(output, (output.shape[0], output.shape[1], 1))\n",
    "#         print(\"G dimensions : \" + str(g.numpy().shape))\n",
    "        \n",
    "#         print(\"\\nATTENTION 1 :-\")\n",
    "        atten1_flattened_output = tf.reshape(conv4_output, (conv4_output.shape[0], conv4_output.shape[1] * conv4_output.shape[2], conv4_output.shape[3]))\n",
    "#         print(\"After Flattening : \" + str(atten1_flattened_output.numpy().shape))\n",
    "        atten1_output = self.atten1_fc(atten1_flattened_output)\n",
    "#         print(\"After FC : \" + str(atten1_output.numpy().shape))\n",
    "        atten1_output = self.perceptron1(get_compatibility(atten1_output, g))\n",
    "#         print(\"After passing through perceptron : \" + str(atten1_output.numpy().shape))\n",
    "        atten1_output = tf.reshape(atten1_output, (atten1_output.shape[0], atten1_output.shape[2], atten1_output.shape[1]))\n",
    "        attention1_values = atten1_output\n",
    "        atten1_output = tf.nn.softmax(atten1_output)\n",
    "#         print(\"After Reshaping and applying Softmax : \" + str(atten1_output.numpy().shape))\n",
    "        atten1_output = tf.matmul(atten1_output, atten1_flattened_output)\n",
    "#         print(\"G_a1 Dimensions : \" + str(atten1_output.numpy().shape))\n",
    "        \n",
    "        #print(\"\\nATTENTION 2 :-\")\n",
    "        atten2_flattened_output = tf.reshape(conv5_output, (conv5_output.shape[0], conv5_output.shape[1] * conv5_output.shape[2], conv5_output.shape[3]))\n",
    "        #print(\"After Flattening : \" + str(atten2_flattened_output.numpy().shape))\n",
    "        atten2_output = self.atten2_fc(atten2_flattened_output)\n",
    "        #print(\"After FC : \" + str(atten2_output.numpy().shape))\n",
    "        atten2_output = self.perceptron2(get_compatibility(atten2_output, g))\n",
    "        #print(\"After Dot Product with G : \" + str(atten2_output.numpy().shape))\n",
    "        atten2_output = tf.reshape(atten2_output, (atten2_output.shape[0], atten2_output.shape[2], atten2_output.shape[1]))\n",
    "        attention2_values = atten2_output\n",
    "        atten2_output = tf.nn.softmax(atten2_output)\n",
    "        #print(\"After Reshaping and applying Softmax : \" + str(atten2_output.numpy().shape))\n",
    "        atten2_output = tf.matmul(atten2_output, atten2_flattened_output)\n",
    "        #print(\"G_a1 Dimensions : \" + str(atten2_output.numpy().shape))\n",
    "        \n",
    "        #print(\"\\nCOMBINING BY OPTION 1 :-\")\n",
    "        output = tf.concat([atten1_output, atten2_output], 2)\n",
    "        output = tf.reshape(output, (output.shape[0], output.shape[2]))\n",
    "        #print(\"Option 1 Dimensions : \" + str(output.numpy().shape))\n",
    "        output = self.out(output)\n",
    "\n",
    "        return output,attention1_values,attention2_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "DISPLAY_STEP = 1\n",
    "VALIDATION_STEP = 5\n",
    "SAVE_STEP = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#used for printing the log with the timestamp\n",
    "logging = tf.logging\n",
    "logging.set_verbosity(logging.INFO)\n",
    "def log_msg(msg):\n",
    "       logging.info(f'{time.ctime()}: {msg}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(net, mode, x, y):\n",
    "    \"\"\"\n",
    "    Computes the loss for a given batch of examples\n",
    "    Args:\n",
    "        mode, string 'train' or 'val'\n",
    "        x, tf tensor representing a batch of images\n",
    "        y, tf tensor representing a batch of labels\n",
    "    Returns:\n",
    "        the loss between the predictions on the images and the groundtruths\n",
    "    \"\"\"\n",
    "    pred,_,_ = net(x)\n",
    "    y = tf.one_hot(y, NUM_CLASSES)\n",
    "\n",
    "    loss_value = tf.losses.softmax_cross_entropy(onehot_labels=y, logits=pred)\n",
    "    weight_decay = tf.reduce_sum(LAMBDA * tf.stack([tf.nn.l2_loss(v) for v in net.variables]))\n",
    "\n",
    "    total_loss = loss_value + weight_decay\n",
    "\n",
    "    tf.contrib.summary.scalar(mode + '/loss', total_loss)\n",
    "\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(net, mode, x, y):\n",
    "    \"\"\"\n",
    "    Computes the accuracy for a given batch of examples\n",
    "    Args:\n",
    "        mode, string 'train' or 'val'\n",
    "        x, tf tensor representing a batch of images\n",
    "        y, tf tensor representing a batch of labels\n",
    "    Returns:\n",
    "        the accuracy of the predictions on the images and the groundtruths\n",
    "    \"\"\"\n",
    "    pred = tf.nn.softmax(net(x)[0])\n",
    "    y = tf.one_hot(y, NUM_CLASSES)\n",
    "\n",
    "    accuracy_value = tf.reduce_sum(\n",
    "                tf.cast(\n",
    "                    tf.equal(\n",
    "                        tf.argmax(pred, axis=1, output_type=tf.int64),\n",
    "                        tf.argmax(y, axis=1, output_type=tf.int64)\n",
    "                    ),\n",
    "                    dtype=tf.float32\n",
    "                ) \n",
    "            ) / float(pred.shape[0].value)\n",
    "\n",
    "    tf.contrib.summary.scalar(mode +'/accuracy', accuracy_value)\n",
    "\n",
    "    return accuracy_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dset = Dataset(X_train, y_train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_dset = Dataset(X_val, y_val, batch_size=valid_set_size, shuffle=False)\n",
    "test_dset = Dataset(X_test, y_test, batch_size=test_set_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8\n",
    "train_dset = Dataset(X_train[:8], y_train[:8], batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (8, 256, 256, 3) (8,)\n"
     ]
    }
   ],
   "source": [
    "# We can iterate through a dataset like this:\n",
    "for t, (x, y) in enumerate(train_dset):\n",
    "    print(t, x.shape, y.shape)\n",
    "#     print(y)\n",
    "    if t > 5: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = X_val[1,:]\n",
    "img = tf.to_float(img.reshape([1,256,256,3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingset = Dataset(X_val[:8], y_val[:8], batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def train(net):\n",
    "    \"\"\"\n",
    "    Training procedure\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    step_time = 0.0\n",
    "    \n",
    "    writer = tf.contrib.summary.create_summary_file_writer(SUMMARY_PATH)\n",
    "#     optimizer = tf.train.MomentumOptimizer(learning_rate=LEARNING_RATE, momentum=MOMENTUM)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate = LEARNING_RATE)\n",
    "    global_step = tf.train.get_or_create_global_step()\n",
    "    epoch = tfe.Variable(0, name='epoch', dtype=tf.float32, trainable=False)\n",
    "    all_variables = (net.variables + optimizer.variables() + [global_step] + [epoch])\n",
    "    \n",
    "    with writer.as_default():\n",
    "        with tf.contrib.summary.record_summaries_every_n_global_steps(DISPLAY_STEP):\n",
    "            for e in range(int(epoch.numpy()), EPOCHS):\n",
    "                tf.assign(epoch, e)\n",
    "                for (batch_i, (images, labels)) in enumerate(train_dset):\n",
    "                    global_step = tf.train.get_global_step()\n",
    "                    step = global_step.numpy() + 1\n",
    "                    images = tf.to_float(images)\n",
    "                    step_start_time = int(round(time.time() * 1000))\n",
    "                    \n",
    "                    optimizer.minimize(lambda: loss(net, 'train', images, labels), global_step=global_step)\n",
    "\n",
    "                    step_end_time = int(round(time.time() * 1000))\n",
    "                    step_time += step_end_time - step_start_time\n",
    "\n",
    "                    if (step % DISPLAY_STEP) == 0:\n",
    "                        l = loss(net, 'train', images, labels)\n",
    "                        a = accuracy(net, 'train', images, labels).numpy()\n",
    "                        log_msg('Epoch: {:03d} Step/Batch: {:09d} Step mean time: {:04d}ms \\nLoss: {:.7f} Training accuracy: {:.4f}'.format(e, step, int(step_time / step), l, a))\n",
    "\n",
    "#                     if (step % VALIDATION_STEP) == 0:\n",
    "#                         for (_, (val_images, val_labels)) in enumerate(val_dset):\n",
    "# #                             val_images, val_labels = tfe.Iterator(val_dset).next()\n",
    "#                             l = loss(net, 'val', val_images, val_labels)\n",
    "#                             a = accuracy(net, 'val', val_images, val_labels).numpy()\n",
    "#                             int_time = time.time() - start_time\n",
    "#                             log_msg('Elapsed time: {:04d}ms --- Loss: {:.7f} Validation accuracy: {:.4f}'.format(int(int_time), l, a))\n",
    "\n",
    "#                     if (step % SAVE_STEP) == 0:\n",
    "#                         tfe.Saver(net.variables).save(os.path.join(CKPT_PATH, 'net.ckpt'), global_step=global_step)\n",
    "#                         log_msg('Variables saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:** tfe.Network is deprecated and will be removed in a future version.\n",
      "\n",
      "Please inherit from `tf.keras.Model`, and see its documentation for details. `tf.keras.Model` should be a drop-in replacement for `tfe.Network` in most cases, but note that `track_layer` is no longer necessary or supported. Instead, `Layer` instances are tracked on attribute assignment (see the section of `tf.keras.Model`'s documentation on subclassing). Since the output of `track_layer` is often assigned to an attribute anyway, most code can be ported by simply removing the `track_layer` calls.\n",
      "\n",
      "`tf.keras.Model` works with all TensorFlow `Layer` instances, including those from `tf.layers`, but switching to the `tf.keras.layers` versions along with the migration to `tf.keras.Model` is recommended, since it will preserve variable names. Feel free to import it with an alias to avoid excess typing :).\n"
     ]
    }
   ],
   "source": [
    "alexnet = AlexNet(training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Deprecation Warning: create_summary_file_writer was renamed to create_file_writer\n",
      "INFO:tensorflow:Sat Nov 17 20:52:51 2018: Epoch: 000 Step/Batch: 000000524 Step mean time: 0004ms \n",
      "Loss: 2.9061646 Training accuracy: 0.2500\n",
      "INFO:tensorflow:Sat Nov 17 20:52:54 2018: Epoch: 000 Step/Batch: 000000525 Step mean time: 0008ms \n",
      "Loss: 3.0212326 Training accuracy: 0.1250\n",
      "INFO:tensorflow:Sat Nov 17 20:52:59 2018: Elapsed time: 0011ms --- Loss: 3.0335603 Validation accuracy: 0.1000\n",
      "INFO:tensorflow:Sat Nov 17 20:53:02 2018: Epoch: 000 Step/Batch: 000000526 Step mean time: 0013ms \n",
      "Loss: 3.0342224 Training accuracy: 0.1250\n",
      "INFO:tensorflow:Sat Nov 17 20:53:06 2018: Epoch: 000 Step/Batch: 000000527 Step mean time: 0017ms \n",
      "Loss: 3.0235653 Training accuracy: 0.0625\n",
      "INFO:tensorflow:Sat Nov 17 20:53:09 2018: Epoch: 000 Step/Batch: 000000528 Step mean time: 0021ms \n",
      "Loss: 3.0299811 Training accuracy: 0.1250\n",
      "INFO:tensorflow:Sat Nov 17 20:53:13 2018: Epoch: 000 Step/Batch: 000000529 Step mean time: 0025ms \n",
      "Loss: 3.0080168 Training accuracy: 0.0625\n",
      "INFO:tensorflow:Sat Nov 17 20:53:16 2018: Epoch: 000 Step/Batch: 000000530 Step mean time: 0030ms \n",
      "Loss: 2.9629700 Training accuracy: 0.1875\n",
      "INFO:tensorflow:Sat Nov 17 20:53:20 2018: Elapsed time: 0033ms --- Loss: 2.9930742 Validation accuracy: 0.1200\n",
      "INFO:tensorflow:Sat Nov 17 20:53:21 2018: Variables saved\n",
      "INFO:tensorflow:Sat Nov 17 20:53:24 2018: Epoch: 000 Step/Batch: 000000531 Step mean time: 0034ms \n",
      "Loss: 3.0087917 Training accuracy: 0.1875\n",
      "INFO:tensorflow:Sat Nov 17 20:53:27 2018: Epoch: 000 Step/Batch: 000000532 Step mean time: 0038ms \n",
      "Loss: 2.9756036 Training accuracy: 0.1875\n",
      "INFO:tensorflow:Sat Nov 17 20:53:31 2018: Epoch: 000 Step/Batch: 000000533 Step mean time: 0042ms \n",
      "Loss: 2.9868822 Training accuracy: 0.1875\n",
      "INFO:tensorflow:Sat Nov 17 20:53:38 2018: Epoch: 000 Step/Batch: 000000534 Step mean time: 0049ms \n",
      "Loss: 2.9631176 Training accuracy: 0.0625\n",
      "INFO:tensorflow:Sat Nov 17 20:53:44 2018: Epoch: 000 Step/Batch: 000000535 Step mean time: 0056ms \n",
      "Loss: 2.9943938 Training accuracy: 0.0000\n",
      "INFO:tensorflow:Sat Nov 17 20:53:53 2018: Elapsed time: 0065ms --- Loss: 2.9611950 Validation accuracy: 0.1400\n",
      "INFO:tensorflow:Sat Nov 17 20:53:56 2018: Epoch: 000 Step/Batch: 000000536 Step mean time: 0060ms \n",
      "Loss: 2.9603405 Training accuracy: 0.0000\n",
      "INFO:tensorflow:Sat Nov 17 20:54:03 2018: Epoch: 001 Step/Batch: 000000537 Step mean time: 0068ms \n",
      "Loss: 2.9199772 Training accuracy: 0.2500\n",
      "INFO:tensorflow:Sat Nov 17 20:54:09 2018: Epoch: 001 Step/Batch: 000000538 Step mean time: 0075ms \n",
      "Loss: 2.9367285 Training accuracy: 0.0625\n",
      "INFO:tensorflow:Sat Nov 17 20:54:16 2018: Epoch: 001 Step/Batch: 000000539 Step mean time: 0083ms \n",
      "Loss: 2.9404106 Training accuracy: 0.0625\n",
      "INFO:tensorflow:Sat Nov 17 20:54:23 2018: Epoch: 001 Step/Batch: 000000540 Step mean time: 0090ms \n",
      "Loss: 2.9122586 Training accuracy: 0.2500\n",
      "INFO:tensorflow:Sat Nov 17 20:54:31 2018: Elapsed time: 0103ms --- Loss: 2.9173758 Validation accuracy: 0.2000\n",
      "INFO:tensorflow:Sat Nov 17 20:54:31 2018: Variables saved\n",
      "INFO:tensorflow:Sat Nov 17 20:54:37 2018: Epoch: 001 Step/Batch: 000000541 Step mean time: 0097ms \n",
      "Loss: 2.9040947 Training accuracy: 0.2500\n",
      "INFO:tensorflow:Sat Nov 17 20:54:44 2018: Epoch: 001 Step/Batch: 000000542 Step mean time: 0105ms \n",
      "Loss: 2.8685029 Training accuracy: 0.3750\n",
      "INFO:tensorflow:Sat Nov 17 20:54:51 2018: Epoch: 001 Step/Batch: 000000543 Step mean time: 0112ms \n",
      "Loss: 2.8751316 Training accuracy: 0.1875\n",
      "INFO:tensorflow:Sat Nov 17 20:54:57 2018: Epoch: 001 Step/Batch: 000000544 Step mean time: 0119ms \n",
      "Loss: 2.8468218 Training accuracy: 0.2500\n",
      "INFO:tensorflow:Sat Nov 17 20:55:04 2018: Epoch: 001 Step/Batch: 000000545 Step mean time: 0127ms \n",
      "Loss: 2.8712795 Training accuracy: 0.1250\n",
      "INFO:tensorflow:Sat Nov 17 20:55:13 2018: Elapsed time: 0145ms --- Loss: 2.8547268 Validation accuracy: 0.2000\n",
      "INFO:tensorflow:Sat Nov 17 20:55:19 2018: Epoch: 001 Step/Batch: 000000546 Step mean time: 0134ms \n",
      "Loss: 2.8139167 Training accuracy: 0.3125\n",
      "INFO:tensorflow:Sat Nov 17 20:55:25 2018: Epoch: 001 Step/Batch: 000000547 Step mean time: 0141ms \n",
      "Loss: 2.7507629 Training accuracy: 0.1250\n",
      "INFO:tensorflow:Sat Nov 17 20:55:32 2018: Epoch: 001 Step/Batch: 000000548 Step mean time: 0148ms \n",
      "Loss: 2.8065805 Training accuracy: 0.1875\n",
      "INFO:tensorflow:Sat Nov 17 20:55:35 2018: Epoch: 001 Step/Batch: 000000549 Step mean time: 0152ms \n",
      "Loss: 2.6413581 Training accuracy: 0.2500\n",
      "INFO:tensorflow:Sat Nov 17 20:55:44 2018: Epoch: 002 Step/Batch: 000000550 Step mean time: 0160ms \n",
      "Loss: 2.7003670 Training accuracy: 0.1250\n",
      "INFO:tensorflow:Sat Nov 17 20:55:57 2018: Elapsed time: 0189ms --- Loss: 2.7804213 Validation accuracy: 0.2000\n",
      "INFO:tensorflow:Sat Nov 17 20:55:57 2018: Variables saved\n",
      "INFO:tensorflow:Sat Nov 17 20:56:07 2018: Epoch: 002 Step/Batch: 000000551 Step mean time: 0170ms \n",
      "Loss: 2.8375602 Training accuracy: 0.0625\n",
      "INFO:tensorflow:Sat Nov 17 20:56:16 2018: Epoch: 002 Step/Batch: 000000552 Step mean time: 0180ms \n",
      "Loss: 2.8805606 Training accuracy: 0.1250\n",
      "INFO:tensorflow:Sat Nov 17 20:56:25 2018: Epoch: 002 Step/Batch: 000000553 Step mean time: 0190ms \n",
      "Loss: 2.8073053 Training accuracy: 0.1250\n",
      "INFO:tensorflow:Sat Nov 17 20:56:35 2018: Epoch: 002 Step/Batch: 000000554 Step mean time: 0200ms \n",
      "Loss: 2.7135792 Training accuracy: 0.3125\n",
      "INFO:tensorflow:Sat Nov 17 20:56:44 2018: Epoch: 002 Step/Batch: 000000555 Step mean time: 0210ms \n",
      "Loss: 2.5028257 Training accuracy: 0.3125\n",
      "INFO:tensorflow:Sat Nov 17 20:56:56 2018: Elapsed time: 0249ms --- Loss: 2.7483864 Validation accuracy: 0.2000\n",
      "INFO:tensorflow:Sat Nov 17 20:57:06 2018: Epoch: 002 Step/Batch: 000000556 Step mean time: 0220ms \n",
      "Loss: 2.6747277 Training accuracy: 0.2500\n",
      "INFO:tensorflow:Sat Nov 17 20:57:15 2018: Epoch: 002 Step/Batch: 000000557 Step mean time: 0230ms \n",
      "Loss: 2.5505061 Training accuracy: 0.2500\n",
      "INFO:tensorflow:Sat Nov 17 20:57:24 2018: Epoch: 002 Step/Batch: 000000558 Step mean time: 0240ms \n",
      "Loss: 2.7909880 Training accuracy: 0.1250\n",
      "INFO:tensorflow:Sat Nov 17 20:57:33 2018: Epoch: 002 Step/Batch: 000000559 Step mean time: 0250ms \n",
      "Loss: 2.6205025 Training accuracy: 0.3125\n",
      "INFO:tensorflow:Sat Nov 17 20:57:43 2018: Epoch: 002 Step/Batch: 000000560 Step mean time: 0259ms \n",
      "Loss: 2.6190262 Training accuracy: 0.2500\n",
      "INFO:tensorflow:Sat Nov 17 20:57:54 2018: Elapsed time: 0306ms --- Loss: 2.7662842 Validation accuracy: 0.1800\n",
      "INFO:tensorflow:Sat Nov 17 20:57:54 2018: Variables saved\n",
      "INFO:tensorflow:Sat Nov 17 20:58:03 2018: Epoch: 002 Step/Batch: 000000561 Step mean time: 0269ms \n",
      "Loss: 2.7326720 Training accuracy: 0.3750\n",
      "INFO:tensorflow:Sat Nov 17 20:58:08 2018: Epoch: 002 Step/Batch: 000000562 Step mean time: 0274ms \n",
      "Loss: 2.3999608 Training accuracy: 0.2500\n",
      "INFO:tensorflow:Sat Nov 17 20:58:17 2018: Epoch: 003 Step/Batch: 000000563 Step mean time: 0283ms \n",
      "Loss: 2.5853992 Training accuracy: 0.1250\n",
      "INFO:tensorflow:Sat Nov 17 20:58:27 2018: Epoch: 003 Step/Batch: 000000564 Step mean time: 0293ms \n",
      "Loss: 2.8202085 Training accuracy: 0.0000\n",
      "INFO:tensorflow:Sat Nov 17 20:58:36 2018: Epoch: 003 Step/Batch: 000000565 Step mean time: 0302ms \n",
      "Loss: 2.8949435 Training accuracy: 0.1250\n",
      "INFO:tensorflow:Sat Nov 17 20:58:47 2018: Elapsed time: 0359ms --- Loss: 2.6741714 Validation accuracy: 0.2000\n",
      "INFO:tensorflow:Sat Nov 17 20:58:56 2018: Epoch: 003 Step/Batch: 000000566 Step mean time: 0312ms \n",
      "Loss: 2.6926222 Training accuracy: 0.2500\n",
      "INFO:tensorflow:Sat Nov 17 20:59:06 2018: Epoch: 003 Step/Batch: 000000567 Step mean time: 0321ms \n",
      "Loss: 2.6631708 Training accuracy: 0.1875\n",
      "INFO:tensorflow:Sat Nov 17 20:59:15 2018: Epoch: 003 Step/Batch: 000000568 Step mean time: 0331ms \n",
      "Loss: 2.4381218 Training accuracy: 0.4375\n",
      "INFO:tensorflow:Sat Nov 17 20:59:25 2018: Epoch: 003 Step/Batch: 000000569 Step mean time: 0340ms \n",
      "Loss: 2.6582482 Training accuracy: 0.1875\n",
      "INFO:tensorflow:Sat Nov 17 20:59:34 2018: Epoch: 003 Step/Batch: 000000570 Step mean time: 0350ms \n",
      "Loss: 2.4875345 Training accuracy: 0.0625\n",
      "INFO:tensorflow:Sat Nov 17 20:59:48 2018: Elapsed time: 0420ms --- Loss: 2.6462150 Validation accuracy: 0.2000\n",
      "INFO:tensorflow:Sat Nov 17 20:59:48 2018: Variables saved\n",
      "INFO:tensorflow:Sat Nov 17 20:59:58 2018: Epoch: 003 Step/Batch: 000000571 Step mean time: 0360ms \n",
      "Loss: 2.6449120 Training accuracy: 0.3125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Sat Nov 17 21:00:07 2018: Epoch: 003 Step/Batch: 000000572 Step mean time: 0369ms \n",
      "Loss: 2.5376608 Training accuracy: 0.2500\n",
      "INFO:tensorflow:Sat Nov 17 21:00:17 2018: Epoch: 003 Step/Batch: 000000573 Step mean time: 0379ms \n",
      "Loss: 2.5701072 Training accuracy: 0.3750\n",
      "INFO:tensorflow:Sat Nov 17 21:00:26 2018: Epoch: 003 Step/Batch: 000000574 Step mean time: 0388ms \n",
      "Loss: 2.5485659 Training accuracy: 0.4375\n",
      "INFO:tensorflow:Sat Nov 17 21:00:31 2018: Epoch: 003 Step/Batch: 000000575 Step mean time: 0392ms \n",
      "Loss: 2.3363218 Training accuracy: 0.2500\n",
      "INFO:tensorflow:Sat Nov 17 21:00:42 2018: Elapsed time: 0474ms --- Loss: 2.6659317 Validation accuracy: 0.1600\n",
      "INFO:tensorflow:Sat Nov 17 21:00:51 2018: Epoch: 004 Step/Batch: 000000576 Step mean time: 0401ms \n",
      "Loss: 2.4546812 Training accuracy: 0.3125\n",
      "INFO:tensorflow:Sat Nov 17 21:01:01 2018: Epoch: 004 Step/Batch: 000000577 Step mean time: 0410ms \n",
      "Loss: 2.7988813 Training accuracy: 0.0625\n",
      "INFO:tensorflow:Sat Nov 17 21:01:11 2018: Epoch: 004 Step/Batch: 000000578 Step mean time: 0420ms \n",
      "Loss: 2.7361922 Training accuracy: 0.1875\n",
      "INFO:tensorflow:Sat Nov 17 21:01:20 2018: Epoch: 004 Step/Batch: 000000579 Step mean time: 0429ms \n",
      "Loss: 2.5790973 Training accuracy: 0.3125\n",
      "INFO:tensorflow:Sat Nov 17 21:01:30 2018: Epoch: 004 Step/Batch: 000000580 Step mean time: 0439ms \n",
      "Loss: 2.5893228 Training accuracy: 0.2500\n",
      "INFO:tensorflow:Sat Nov 17 21:01:41 2018: Elapsed time: 0533ms --- Loss: 2.5861361 Validation accuracy: 0.2400\n",
      "INFO:tensorflow:Sat Nov 17 21:01:41 2018: Variables saved\n",
      "INFO:tensorflow:Sat Nov 17 21:01:52 2018: Epoch: 004 Step/Batch: 000000581 Step mean time: 0449ms \n",
      "Loss: 2.3507009 Training accuracy: 0.3750\n",
      "INFO:tensorflow:Sat Nov 17 21:02:02 2018: Epoch: 004 Step/Batch: 000000582 Step mean time: 0459ms \n",
      "Loss: 2.4819529 Training accuracy: 0.3125\n",
      "INFO:tensorflow:Sat Nov 17 21:02:13 2018: Epoch: 004 Step/Batch: 000000583 Step mean time: 0470ms \n",
      "Loss: 2.5835948 Training accuracy: 0.1250\n",
      "INFO:tensorflow:Sat Nov 17 21:02:23 2018: Epoch: 004 Step/Batch: 000000584 Step mean time: 0479ms \n",
      "Loss: 2.5702369 Training accuracy: 0.2500\n",
      "INFO:tensorflow:Sat Nov 17 21:02:32 2018: Epoch: 004 Step/Batch: 000000585 Step mean time: 0488ms \n",
      "Loss: 2.4866362 Training accuracy: 0.2500\n",
      "INFO:tensorflow:Sat Nov 17 21:02:43 2018: Elapsed time: 0596ms --- Loss: 2.5941210 Validation accuracy: 0.2000\n",
      "INFO:tensorflow:Sat Nov 17 21:02:54 2018: Epoch: 004 Step/Batch: 000000586 Step mean time: 0498ms \n",
      "Loss: 2.5932441 Training accuracy: 0.3125\n",
      "INFO:tensorflow:Sat Nov 17 21:03:04 2018: Epoch: 004 Step/Batch: 000000587 Step mean time: 0508ms \n",
      "Loss: 2.4567561 Training accuracy: 0.5000\n",
      "INFO:tensorflow:Sat Nov 17 21:03:10 2018: Epoch: 004 Step/Batch: 000000588 Step mean time: 0513ms \n",
      "Loss: 2.2819915 Training accuracy: 0.2500\n",
      "INFO:tensorflow:Sat Nov 17 21:03:20 2018: Epoch: 005 Step/Batch: 000000589 Step mean time: 0524ms \n",
      "Loss: 2.3339796 Training accuracy: 0.2500\n",
      "INFO:tensorflow:Sat Nov 17 21:03:30 2018: Epoch: 005 Step/Batch: 000000590 Step mean time: 0533ms \n",
      "Loss: 2.7524490 Training accuracy: 0.0625\n",
      "INFO:tensorflow:Sat Nov 17 21:03:43 2018: Elapsed time: 0656ms --- Loss: 2.5416067 Validation accuracy: 0.2200\n",
      "INFO:tensorflow:Sat Nov 17 21:03:44 2018: Variables saved\n",
      "INFO:tensorflow:Sat Nov 17 21:03:54 2018: Epoch: 005 Step/Batch: 000000591 Step mean time: 0543ms \n",
      "Loss: 2.6061647 Training accuracy: 0.2500\n",
      "INFO:tensorflow:Sat Nov 17 21:04:04 2018: Epoch: 005 Step/Batch: 000000592 Step mean time: 0553ms \n",
      "Loss: 2.6079679 Training accuracy: 0.2500\n",
      "INFO:tensorflow:Sat Nov 17 21:04:14 2018: Epoch: 005 Step/Batch: 000000593 Step mean time: 0562ms \n",
      "Loss: 2.5141945 Training accuracy: 0.3750\n",
      "INFO:tensorflow:Sat Nov 17 21:04:23 2018: Epoch: 005 Step/Batch: 000000594 Step mean time: 0571ms \n",
      "Loss: 2.4466443 Training accuracy: 0.3750\n",
      "INFO:tensorflow:Sat Nov 17 21:04:32 2018: Epoch: 005 Step/Batch: 000000595 Step mean time: 0579ms \n",
      "Loss: 2.5319731 Training accuracy: 0.2500\n",
      "INFO:tensorflow:Sat Nov 17 21:04:44 2018: Elapsed time: 0716ms --- Loss: 2.5670860 Validation accuracy: 0.1600\n",
      "INFO:tensorflow:Sat Nov 17 21:04:54 2018: Epoch: 005 Step/Batch: 000000596 Step mean time: 0589ms \n",
      "Loss: 2.3399315 Training accuracy: 0.2500\n",
      "INFO:tensorflow:Sat Nov 17 21:05:04 2018: Epoch: 005 Step/Batch: 000000597 Step mean time: 0598ms \n",
      "Loss: 2.4509845 Training accuracy: 0.3750\n",
      "INFO:tensorflow:Sat Nov 17 21:05:14 2018: Epoch: 005 Step/Batch: 000000598 Step mean time: 0607ms \n",
      "Loss: 2.3295367 Training accuracy: 0.3750\n",
      "INFO:tensorflow:Sat Nov 17 21:05:24 2018: Epoch: 005 Step/Batch: 000000599 Step mean time: 0616ms \n",
      "Loss: 2.5183272 Training accuracy: 0.2500\n",
      "INFO:tensorflow:Sat Nov 17 21:05:34 2018: Epoch: 005 Step/Batch: 000000600 Step mean time: 0625ms \n",
      "Loss: 2.2956724 Training accuracy: 0.4375\n",
      "INFO:tensorflow:Sat Nov 17 21:05:45 2018: Elapsed time: 0777ms --- Loss: 2.5329556 Validation accuracy: 0.2000\n",
      "INFO:tensorflow:Sat Nov 17 21:05:46 2018: Variables saved\n",
      "INFO:tensorflow:Sat Nov 17 21:05:50 2018: Epoch: 005 Step/Batch: 000000601 Step mean time: 0629ms \n",
      "Loss: 2.1857693 Training accuracy: 0.2500\n",
      "INFO:tensorflow:Sat Nov 17 21:06:00 2018: Epoch: 006 Step/Batch: 000000602 Step mean time: 0638ms \n",
      "Loss: 2.0900161 Training accuracy: 0.5625\n",
      "INFO:tensorflow:Sat Nov 17 21:06:10 2018: Epoch: 006 Step/Batch: 000000603 Step mean time: 0647ms \n",
      "Loss: 2.7357280 Training accuracy: 0.1250\n",
      "INFO:tensorflow:Sat Nov 17 21:06:19 2018: Epoch: 006 Step/Batch: 000000604 Step mean time: 0655ms \n",
      "Loss: 2.5465877 Training accuracy: 0.3125\n",
      "INFO:tensorflow:Sat Nov 17 21:06:29 2018: Epoch: 006 Step/Batch: 000000605 Step mean time: 0664ms \n",
      "Loss: 2.4050548 Training accuracy: 0.2500\n",
      "INFO:tensorflow:Sat Nov 17 21:06:40 2018: Elapsed time: 0832ms --- Loss: 2.4756339 Validation accuracy: 0.2200\n",
      "INFO:tensorflow:Sat Nov 17 21:06:49 2018: Epoch: 006 Step/Batch: 000000606 Step mean time: 0672ms \n",
      "Loss: 2.4292512 Training accuracy: 0.3750\n",
      "INFO:tensorflow:Sat Nov 17 21:06:59 2018: Epoch: 006 Step/Batch: 000000607 Step mean time: 0680ms \n",
      "Loss: 2.3140903 Training accuracy: 0.3750\n",
      "INFO:tensorflow:Sat Nov 17 21:07:08 2018: Epoch: 006 Step/Batch: 000000608 Step mean time: 0689ms \n",
      "Loss: 2.3058567 Training accuracy: 0.3750\n",
      "INFO:tensorflow:Sat Nov 17 21:07:17 2018: Epoch: 006 Step/Batch: 000000609 Step mean time: 0697ms \n",
      "Loss: 2.1961861 Training accuracy: 0.3125\n",
      "INFO:tensorflow:Sat Nov 17 21:07:26 2018: Epoch: 006 Step/Batch: 000000610 Step mean time: 0705ms \n",
      "Loss: 2.3440893 Training accuracy: 0.3750\n",
      "INFO:tensorflow:Sat Nov 17 21:07:38 2018: Elapsed time: 0890ms --- Loss: 2.5052056 Validation accuracy: 0.2600\n",
      "INFO:tensorflow:Sat Nov 17 21:07:38 2018: Variables saved\n",
      "INFO:tensorflow:Sat Nov 17 21:07:49 2018: Epoch: 006 Step/Batch: 000000611 Step mean time: 0714ms \n",
      "Loss: 2.1903601 Training accuracy: 0.3125\n",
      "INFO:tensorflow:Sat Nov 17 21:07:59 2018: Epoch: 006 Step/Batch: 000000612 Step mean time: 0724ms \n",
      "Loss: 2.4570799 Training accuracy: 0.3750\n",
      "INFO:tensorflow:Sat Nov 17 21:08:09 2018: Epoch: 006 Step/Batch: 000000613 Step mean time: 0732ms \n",
      "Loss: 2.2418478 Training accuracy: 0.4375\n",
      "INFO:tensorflow:Sat Nov 17 21:08:13 2018: Epoch: 006 Step/Batch: 000000614 Step mean time: 0735ms \n",
      "Loss: 1.9975317 Training accuracy: 0.3750\n",
      "INFO:tensorflow:Sat Nov 17 21:08:23 2018: Epoch: 007 Step/Batch: 000000615 Step mean time: 0744ms \n",
      "Loss: 1.9230623 Training accuracy: 0.4375\n",
      "INFO:tensorflow:Sat Nov 17 21:08:36 2018: Elapsed time: 0948ms --- Loss: 2.5020266 Validation accuracy: 0.2600\n",
      "INFO:tensorflow:Sat Nov 17 21:08:45 2018: Epoch: 007 Step/Batch: 000000616 Step mean time: 0752ms \n",
      "Loss: 2.6983879 Training accuracy: 0.1250\n",
      "INFO:tensorflow:Sat Nov 17 21:08:55 2018: Epoch: 007 Step/Batch: 000000617 Step mean time: 0761ms \n",
      "Loss: 2.3919685 Training accuracy: 0.2500\n",
      "INFO:tensorflow:Sat Nov 17 21:09:05 2018: Epoch: 007 Step/Batch: 000000618 Step mean time: 0769ms \n",
      "Loss: 2.3345397 Training accuracy: 0.3125\n",
      "INFO:tensorflow:Sat Nov 17 21:09:14 2018: Epoch: 007 Step/Batch: 000000619 Step mean time: 0777ms \n",
      "Loss: 2.3491702 Training accuracy: 0.3125\n",
      "INFO:tensorflow:Sat Nov 17 21:09:24 2018: Epoch: 007 Step/Batch: 000000620 Step mean time: 0786ms \n",
      "Loss: 2.1959667 Training accuracy: 0.4375\n",
      "INFO:tensorflow:Sat Nov 17 21:09:36 2018: Elapsed time: 1008ms --- Loss: 2.5600023 Validation accuracy: 0.1800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Sat Nov 17 21:09:37 2018: Variables saved\n",
      "INFO:tensorflow:Sat Nov 17 21:09:47 2018: Epoch: 007 Step/Batch: 000000621 Step mean time: 0795ms \n",
      "Loss: 2.2977057 Training accuracy: 0.5625\n",
      "INFO:tensorflow:Sat Nov 17 21:09:57 2018: Epoch: 007 Step/Batch: 000000622 Step mean time: 0804ms \n",
      "Loss: 2.0453110 Training accuracy: 0.6875\n",
      "INFO:tensorflow:Sat Nov 17 21:10:08 2018: Epoch: 007 Step/Batch: 000000623 Step mean time: 0813ms \n",
      "Loss: 2.4379005 Training accuracy: 0.3750\n",
      "INFO:tensorflow:Sat Nov 17 21:10:18 2018: Epoch: 007 Step/Batch: 000000624 Step mean time: 0821ms \n",
      "Loss: 2.1597006 Training accuracy: 0.3750\n",
      "INFO:tensorflow:Sat Nov 17 21:10:28 2018: Epoch: 007 Step/Batch: 000000625 Step mean time: 0830ms \n",
      "Loss: 2.3942926 Training accuracy: 0.3750\n",
      "INFO:tensorflow:Sat Nov 17 21:10:41 2018: Elapsed time: 1073ms --- Loss: 2.4570012 Validation accuracy: 0.2800\n",
      "INFO:tensorflow:Sat Nov 17 21:10:51 2018: Epoch: 007 Step/Batch: 000000626 Step mean time: 0838ms \n",
      "Loss: 2.1038661 Training accuracy: 0.4375\n",
      "INFO:tensorflow:Sat Nov 17 21:10:56 2018: Epoch: 007 Step/Batch: 000000627 Step mean time: 0842ms \n",
      "Loss: 1.8766245 Training accuracy: 0.5000\n",
      "INFO:tensorflow:Sat Nov 17 21:11:07 2018: Epoch: 008 Step/Batch: 000000628 Step mean time: 0851ms \n",
      "Loss: 1.8034210 Training accuracy: 0.5000\n",
      "INFO:tensorflow:Sat Nov 17 21:11:17 2018: Epoch: 008 Step/Batch: 000000629 Step mean time: 0860ms \n",
      "Loss: 2.6482408 Training accuracy: 0.1250\n",
      "INFO:tensorflow:Sat Nov 17 21:11:27 2018: Epoch: 008 Step/Batch: 000000630 Step mean time: 0869ms \n",
      "Loss: 2.4288042 Training accuracy: 0.2500\n",
      "INFO:tensorflow:Sat Nov 17 21:11:40 2018: Elapsed time: 1132ms --- Loss: 2.5397255 Validation accuracy: 0.2400\n",
      "INFO:tensorflow:Sat Nov 17 21:11:40 2018: Variables saved\n",
      "INFO:tensorflow:Sat Nov 17 21:11:50 2018: Epoch: 008 Step/Batch: 000000631 Step mean time: 0877ms \n",
      "Loss: 2.3871269 Training accuracy: 0.3125\n",
      "INFO:tensorflow:Sat Nov 17 21:12:00 2018: Epoch: 008 Step/Batch: 000000632 Step mean time: 0885ms \n",
      "Loss: 2.2099802 Training accuracy: 0.3125\n",
      "INFO:tensorflow:Sat Nov 17 21:12:11 2018: Epoch: 008 Step/Batch: 000000633 Step mean time: 0894ms \n",
      "Loss: 2.1143885 Training accuracy: 0.4375\n",
      "INFO:tensorflow:Sat Nov 17 21:12:20 2018: Epoch: 008 Step/Batch: 000000634 Step mean time: 0902ms \n",
      "Loss: 2.1649840 Training accuracy: 0.5000\n",
      "INFO:tensorflow:Sat Nov 17 21:12:31 2018: Epoch: 008 Step/Batch: 000000635 Step mean time: 0911ms \n",
      "Loss: 1.9964421 Training accuracy: 0.5625\n",
      "INFO:tensorflow:Sat Nov 17 21:12:44 2018: Elapsed time: 1196ms --- Loss: 2.5026538 Validation accuracy: 0.1800\n",
      "INFO:tensorflow:Sat Nov 17 21:12:54 2018: Epoch: 008 Step/Batch: 000000636 Step mean time: 0919ms \n",
      "Loss: 2.2611666 Training accuracy: 0.5000\n",
      "INFO:tensorflow:Sat Nov 17 21:13:03 2018: Epoch: 008 Step/Batch: 000000637 Step mean time: 0927ms \n",
      "Loss: 2.1623983 Training accuracy: 0.3750\n",
      "INFO:tensorflow:Sat Nov 17 21:13:13 2018: Epoch: 008 Step/Batch: 000000638 Step mean time: 0935ms \n",
      "Loss: 2.3733842 Training accuracy: 0.3750\n",
      "INFO:tensorflow:Sat Nov 17 21:13:23 2018: Epoch: 008 Step/Batch: 000000639 Step mean time: 0943ms \n",
      "Loss: 2.1378341 Training accuracy: 0.5000\n",
      "INFO:tensorflow:Sat Nov 17 21:13:28 2018: Epoch: 008 Step/Batch: 000000640 Step mean time: 0946ms \n",
      "Loss: 1.8707762 Training accuracy: 0.6250\n",
      "INFO:tensorflow:Sat Nov 17 21:13:40 2018: Elapsed time: 1252ms --- Loss: 2.4508605 Validation accuracy: 0.2800\n",
      "INFO:tensorflow:Sat Nov 17 21:13:41 2018: Variables saved\n",
      "INFO:tensorflow:Sat Nov 17 21:13:51 2018: Epoch: 009 Step/Batch: 000000641 Step mean time: 0954ms \n",
      "Loss: 1.7522146 Training accuracy: 0.4375\n",
      "INFO:tensorflow:Sat Nov 17 21:14:01 2018: Epoch: 009 Step/Batch: 000000642 Step mean time: 0962ms \n",
      "Loss: 2.3967488 Training accuracy: 0.1875\n",
      "INFO:tensorflow:Sat Nov 17 21:14:11 2018: Epoch: 009 Step/Batch: 000000643 Step mean time: 0970ms \n",
      "Loss: 2.2365751 Training accuracy: 0.2500\n",
      "INFO:tensorflow:Sat Nov 17 21:14:22 2018: Epoch: 009 Step/Batch: 000000644 Step mean time: 0979ms \n",
      "Loss: 2.2372961 Training accuracy: 0.5000\n",
      "INFO:tensorflow:Sat Nov 17 21:14:33 2018: Epoch: 009 Step/Batch: 000000645 Step mean time: 0988ms \n",
      "Loss: 2.1021495 Training accuracy: 0.3125\n",
      "INFO:tensorflow:Sat Nov 17 21:14:46 2018: Elapsed time: 1319ms --- Loss: 2.5746720 Validation accuracy: 0.2600\n",
      "INFO:tensorflow:Sat Nov 17 21:14:56 2018: Epoch: 009 Step/Batch: 000000646 Step mean time: 0996ms \n",
      "Loss: 2.0723481 Training accuracy: 0.4375\n",
      "INFO:tensorflow:Sat Nov 17 21:15:06 2018: Epoch: 009 Step/Batch: 000000647 Step mean time: 1004ms \n",
      "Loss: 2.0660691 Training accuracy: 0.4375\n",
      "INFO:tensorflow:Sat Nov 17 21:15:15 2018: Epoch: 009 Step/Batch: 000000648 Step mean time: 1011ms \n",
      "Loss: 1.9449298 Training accuracy: 0.4375\n",
      "INFO:tensorflow:Sat Nov 17 21:15:25 2018: Epoch: 009 Step/Batch: 000000649 Step mean time: 1019ms \n",
      "Loss: 2.0965738 Training accuracy: 0.4375\n",
      "INFO:tensorflow:Sat Nov 17 21:15:35 2018: Epoch: 009 Step/Batch: 000000650 Step mean time: 1026ms \n",
      "Loss: 1.9068810 Training accuracy: 0.5000\n",
      "INFO:tensorflow:Sat Nov 17 21:15:47 2018: Elapsed time: 1379ms --- Loss: 2.4655211 Validation accuracy: 0.3200\n",
      "INFO:tensorflow:Sat Nov 17 21:15:47 2018: Variables saved\n",
      "INFO:tensorflow:Sat Nov 17 21:15:57 2018: Epoch: 009 Step/Batch: 000000651 Step mean time: 1034ms \n",
      "Loss: 2.2288716 Training accuracy: 0.4375\n",
      "INFO:tensorflow:Sat Nov 17 21:16:06 2018: Epoch: 009 Step/Batch: 000000652 Step mean time: 1041ms \n",
      "Loss: 2.0265286 Training accuracy: 0.5000\n",
      "INFO:tensorflow:Sat Nov 17 21:16:11 2018: Epoch: 009 Step/Batch: 000000653 Step mean time: 1044ms \n",
      "Loss: 1.7014425 Training accuracy: 0.6250\n",
      "INFO:tensorflow:Sat Nov 17 21:16:22 2018: Epoch: 010 Step/Batch: 000000654 Step mean time: 1052ms \n",
      "Loss: 1.6846211 Training accuracy: 0.5000\n",
      "INFO:tensorflow:Sat Nov 17 21:16:32 2018: Epoch: 010 Step/Batch: 000000655 Step mean time: 1061ms \n",
      "Loss: 2.1789246 Training accuracy: 0.2500\n",
      "INFO:tensorflow:Sat Nov 17 21:16:47 2018: Elapsed time: 1439ms --- Loss: 2.5309169 Validation accuracy: 0.2200\n",
      "INFO:tensorflow:Sat Nov 17 21:16:58 2018: Epoch: 010 Step/Batch: 000000656 Step mean time: 1070ms \n",
      "Loss: 2.1097736 Training accuracy: 0.3750\n",
      "INFO:tensorflow:Sat Nov 17 21:17:09 2018: Epoch: 010 Step/Batch: 000000657 Step mean time: 1078ms \n",
      "Loss: 1.9720926 Training accuracy: 0.5625\n",
      "INFO:tensorflow:Sat Nov 17 21:17:20 2018: Epoch: 010 Step/Batch: 000000658 Step mean time: 1087ms \n",
      "Loss: 2.0146427 Training accuracy: 0.3750\n",
      "INFO:tensorflow:Sat Nov 17 21:17:31 2018: Epoch: 010 Step/Batch: 000000659 Step mean time: 1096ms \n",
      "Loss: 1.8548375 Training accuracy: 0.5000\n",
      "INFO:tensorflow:Sat Nov 17 21:17:41 2018: Epoch: 010 Step/Batch: 000000660 Step mean time: 1103ms \n",
      "Loss: 1.8549616 Training accuracy: 0.6250\n",
      "INFO:tensorflow:Sat Nov 17 21:17:56 2018: Elapsed time: 1508ms --- Loss: 2.5679004 Validation accuracy: 0.2600\n",
      "INFO:tensorflow:Sat Nov 17 21:17:56 2018: Variables saved\n",
      "INFO:tensorflow:Sat Nov 17 21:18:06 2018: Epoch: 010 Step/Batch: 000000661 Step mean time: 1111ms \n",
      "Loss: 1.7560838 Training accuracy: 0.7500\n",
      "INFO:tensorflow:Sat Nov 17 21:18:16 2018: Epoch: 010 Step/Batch: 000000662 Step mean time: 1118ms \n",
      "Loss: 2.0669327 Training accuracy: 0.5000\n",
      "INFO:tensorflow:Sat Nov 17 21:18:26 2018: Epoch: 010 Step/Batch: 000000663 Step mean time: 1126ms \n",
      "Loss: 1.8191259 Training accuracy: 0.5625\n",
      "INFO:tensorflow:Sat Nov 17 21:18:36 2018: Epoch: 010 Step/Batch: 000000664 Step mean time: 1133ms \n",
      "Loss: 1.9471463 Training accuracy: 0.5000\n",
      "INFO:tensorflow:Sat Nov 17 21:18:46 2018: Epoch: 010 Step/Batch: 000000665 Step mean time: 1141ms \n",
      "Loss: 1.8900378 Training accuracy: 0.5000\n",
      "INFO:tensorflow:Sat Nov 17 21:18:59 2018: Elapsed time: 1571ms --- Loss: 2.6025655 Validation accuracy: 0.2600\n",
      "INFO:tensorflow:Sat Nov 17 21:19:04 2018: Epoch: 010 Step/Batch: 000000666 Step mean time: 1144ms \n",
      "Loss: 1.5481541 Training accuracy: 0.6250\n",
      "INFO:tensorflow:Sat Nov 17 21:19:14 2018: Epoch: 011 Step/Batch: 000000667 Step mean time: 1152ms \n",
      "Loss: 1.5553856 Training accuracy: 0.6875\n",
      "INFO:tensorflow:Sat Nov 17 21:19:25 2018: Epoch: 011 Step/Batch: 000000668 Step mean time: 1160ms \n",
      "Loss: 2.1143291 Training accuracy: 0.3750\n",
      "INFO:tensorflow:Sat Nov 17 21:19:35 2018: Epoch: 011 Step/Batch: 000000669 Step mean time: 1167ms \n",
      "Loss: 2.0003161 Training accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Sat Nov 17 21:19:46 2018: Epoch: 011 Step/Batch: 000000670 Step mean time: 1176ms \n",
      "Loss: 1.8499116 Training accuracy: 0.4375\n",
      "INFO:tensorflow:Sat Nov 17 21:19:59 2018: Elapsed time: 1631ms --- Loss: 2.6637340 Validation accuracy: 0.2000\n",
      "INFO:tensorflow:Sat Nov 17 21:20:00 2018: Variables saved\n",
      "INFO:tensorflow:Sat Nov 17 21:20:10 2018: Epoch: 011 Step/Batch: 000000671 Step mean time: 1184ms \n",
      "Loss: 1.8731762 Training accuracy: 0.4375\n",
      "INFO:tensorflow:Sat Nov 17 21:20:21 2018: Epoch: 011 Step/Batch: 000000672 Step mean time: 1192ms \n",
      "Loss: 1.6822212 Training accuracy: 0.5000\n",
      "INFO:tensorflow:Sat Nov 17 21:20:32 2018: Epoch: 011 Step/Batch: 000000673 Step mean time: 1200ms \n",
      "Loss: 1.7546399 Training accuracy: 0.6250\n",
      "INFO:tensorflow:Sat Nov 17 21:20:42 2018: Epoch: 011 Step/Batch: 000000674 Step mean time: 1207ms \n",
      "Loss: 1.6579763 Training accuracy: 0.6250\n",
      "INFO:tensorflow:Sat Nov 17 21:20:54 2018: Epoch: 011 Step/Batch: 000000675 Step mean time: 1216ms \n",
      "Loss: 2.0095317 Training accuracy: 0.3750\n",
      "INFO:tensorflow:Sat Nov 17 21:21:08 2018: Elapsed time: 1700ms --- Loss: 2.5855589 Validation accuracy: 0.3400\n",
      "INFO:tensorflow:Sat Nov 17 21:21:18 2018: Epoch: 011 Step/Batch: 000000676 Step mean time: 1224ms \n",
      "Loss: 1.8469610 Training accuracy: 0.6250\n",
      "INFO:tensorflow:Sat Nov 17 21:21:29 2018: Epoch: 011 Step/Batch: 000000677 Step mean time: 1233ms \n",
      "Loss: 1.7757809 Training accuracy: 0.6250\n",
      "INFO:tensorflow:Sat Nov 17 21:21:40 2018: Epoch: 011 Step/Batch: 000000678 Step mean time: 1240ms \n",
      "Loss: 1.7957224 Training accuracy: 0.6250\n",
      "INFO:tensorflow:Sat Nov 17 21:21:45 2018: Epoch: 011 Step/Batch: 000000679 Step mean time: 1244ms \n",
      "Loss: 1.4057727 Training accuracy: 0.7500\n",
      "INFO:tensorflow:Sat Nov 17 21:21:55 2018: Epoch: 012 Step/Batch: 000000680 Step mean time: 1251ms \n",
      "Loss: 1.4420946 Training accuracy: 0.8125\n",
      "INFO:tensorflow:Sat Nov 17 21:22:08 2018: Elapsed time: 1761ms --- Loss: 2.7778590 Validation accuracy: 0.2400\n",
      "INFO:tensorflow:Sat Nov 17 21:22:09 2018: Variables saved\n",
      "INFO:tensorflow:Sat Nov 17 21:22:19 2018: Epoch: 012 Step/Batch: 000000681 Step mean time: 1259ms \n",
      "Loss: 2.0717797 Training accuracy: 0.3125\n",
      "INFO:tensorflow:Sat Nov 17 21:22:29 2018: Epoch: 012 Step/Batch: 000000682 Step mean time: 1266ms \n",
      "Loss: 1.9914086 Training accuracy: 0.3750\n",
      "INFO:tensorflow:Sat Nov 17 21:22:40 2018: Epoch: 012 Step/Batch: 000000683 Step mean time: 1273ms \n",
      "Loss: 1.8892515 Training accuracy: 0.6250\n",
      "INFO:tensorflow:Sat Nov 17 21:22:50 2018: Epoch: 012 Step/Batch: 000000684 Step mean time: 1280ms \n",
      "Loss: 1.8746583 Training accuracy: 0.4375\n",
      "INFO:tensorflow:Sat Nov 17 21:23:00 2018: Epoch: 012 Step/Batch: 000000685 Step mean time: 1288ms \n",
      "Loss: 1.5930948 Training accuracy: 0.5625\n",
      "INFO:tensorflow:Sat Nov 17 21:23:13 2018: Elapsed time: 1825ms --- Loss: 2.8515735 Validation accuracy: 0.1800\n",
      "INFO:tensorflow:Sat Nov 17 21:23:23 2018: Epoch: 012 Step/Batch: 000000686 Step mean time: 1295ms \n",
      "Loss: 1.6298962 Training accuracy: 0.6250\n",
      "INFO:tensorflow:Sat Nov 17 21:23:33 2018: Epoch: 012 Step/Batch: 000000687 Step mean time: 1302ms \n",
      "Loss: 1.5808024 Training accuracy: 0.5625\n",
      "INFO:tensorflow:Sat Nov 17 21:23:43 2018: Epoch: 012 Step/Batch: 000000688 Step mean time: 1309ms \n",
      "Loss: 1.8673302 Training accuracy: 0.3750\n",
      "INFO:tensorflow:Sat Nov 17 21:23:53 2018: Epoch: 012 Step/Batch: 000000689 Step mean time: 1316ms \n",
      "Loss: 1.8348442 Training accuracy: 0.6250\n",
      "INFO:tensorflow:Sat Nov 17 21:24:04 2018: Epoch: 012 Step/Batch: 000000690 Step mean time: 1324ms \n",
      "Loss: 1.7151539 Training accuracy: 0.5625\n",
      "INFO:tensorflow:Sat Nov 17 21:24:17 2018: Elapsed time: 1889ms --- Loss: 2.6783977 Validation accuracy: 0.2800\n",
      "INFO:tensorflow:Sat Nov 17 21:24:18 2018: Variables saved\n",
      "INFO:tensorflow:Sat Nov 17 21:24:28 2018: Epoch: 012 Step/Batch: 000000691 Step mean time: 1331ms \n",
      "Loss: 1.8664269 Training accuracy: 0.4375\n",
      "INFO:tensorflow:Sat Nov 17 21:24:33 2018: Epoch: 012 Step/Batch: 000000692 Step mean time: 1334ms \n",
      "Loss: 1.5163596 Training accuracy: 0.6250\n",
      "INFO:tensorflow:Sat Nov 17 21:24:44 2018: Epoch: 013 Step/Batch: 000000693 Step mean time: 1341ms \n",
      "Loss: 1.2831140 Training accuracy: 0.8125\n",
      "INFO:tensorflow:Sat Nov 17 21:24:54 2018: Epoch: 013 Step/Batch: 000000694 Step mean time: 1348ms \n",
      "Loss: 1.8393836 Training accuracy: 0.5625\n",
      "INFO:tensorflow:Sat Nov 17 21:25:04 2018: Epoch: 013 Step/Batch: 000000695 Step mean time: 1355ms \n",
      "Loss: 1.6797290 Training accuracy: 0.5000\n",
      "INFO:tensorflow:Sat Nov 17 21:25:17 2018: Elapsed time: 1950ms --- Loss: 2.7312553 Validation accuracy: 0.1800\n",
      "INFO:tensorflow:Sat Nov 17 21:25:28 2018: Epoch: 013 Step/Batch: 000000696 Step mean time: 1362ms \n",
      "Loss: 1.6148419 Training accuracy: 0.6875\n",
      "INFO:tensorflow:Sat Nov 17 21:25:38 2018: Epoch: 013 Step/Batch: 000000697 Step mean time: 1369ms \n",
      "Loss: 1.8302143 Training accuracy: 0.3750\n",
      "INFO:tensorflow:Sat Nov 17 21:25:49 2018: Epoch: 013 Step/Batch: 000000698 Step mean time: 1377ms \n",
      "Loss: 1.7060981 Training accuracy: 0.4375\n",
      "INFO:tensorflow:Sat Nov 17 21:25:59 2018: Epoch: 013 Step/Batch: 000000699 Step mean time: 1384ms \n",
      "Loss: 1.6587920 Training accuracy: 0.5000\n",
      "INFO:tensorflow:Sat Nov 17 21:26:09 2018: Epoch: 013 Step/Batch: 000000700 Step mean time: 1391ms \n",
      "Loss: 1.7726476 Training accuracy: 0.3750\n",
      "INFO:tensorflow:Sat Nov 17 21:26:22 2018: Elapsed time: 2014ms --- Loss: 2.8085668 Validation accuracy: 0.2400\n",
      "INFO:tensorflow:Sat Nov 17 21:26:23 2018: Variables saved\n",
      "INFO:tensorflow:Sat Nov 17 21:26:34 2018: Epoch: 013 Step/Batch: 000000701 Step mean time: 1399ms \n",
      "Loss: 1.8889964 Training accuracy: 0.5000\n",
      "INFO:tensorflow:Sat Nov 17 21:26:46 2018: Epoch: 013 Step/Batch: 000000702 Step mean time: 1407ms \n",
      "Loss: 1.6649783 Training accuracy: 0.6250\n",
      "INFO:tensorflow:Sat Nov 17 21:26:56 2018: Epoch: 013 Step/Batch: 000000703 Step mean time: 1414ms \n",
      "Loss: 1.3771167 Training accuracy: 0.6250\n",
      "INFO:tensorflow:Sat Nov 17 21:27:06 2018: Epoch: 013 Step/Batch: 000000704 Step mean time: 1421ms \n",
      "Loss: 1.8904946 Training accuracy: 0.5000\n",
      "INFO:tensorflow:Sat Nov 17 21:27:11 2018: Epoch: 013 Step/Batch: 000000705 Step mean time: 1423ms \n",
      "Loss: 1.6177385 Training accuracy: 0.3750\n",
      "INFO:tensorflow:Sat Nov 17 21:27:24 2018: Elapsed time: 2076ms --- Loss: 2.6160784 Validation accuracy: 0.2400\n",
      "INFO:tensorflow:Sat Nov 17 21:27:34 2018: Epoch: 014 Step/Batch: 000000706 Step mean time: 1430ms \n",
      "Loss: 1.2650447 Training accuracy: 0.8125\n",
      "INFO:tensorflow:Sat Nov 17 21:27:45 2018: Epoch: 014 Step/Batch: 000000707 Step mean time: 1437ms \n",
      "Loss: 1.6121470 Training accuracy: 0.7500\n",
      "INFO:tensorflow:Sat Nov 17 21:27:55 2018: Epoch: 014 Step/Batch: 000000708 Step mean time: 1444ms \n",
      "Loss: 1.5518277 Training accuracy: 0.5625\n",
      "INFO:tensorflow:Sat Nov 17 21:28:05 2018: Epoch: 014 Step/Batch: 000000709 Step mean time: 1451ms \n",
      "Loss: 1.5943816 Training accuracy: 0.6250\n",
      "INFO:tensorflow:Sat Nov 17 21:28:15 2018: Epoch: 014 Step/Batch: 000000710 Step mean time: 1458ms \n",
      "Loss: 1.7833323 Training accuracy: 0.5625\n",
      "INFO:tensorflow:Sat Nov 17 21:28:29 2018: Elapsed time: 2141ms --- Loss: 2.9029448 Validation accuracy: 0.1600\n",
      "INFO:tensorflow:Sat Nov 17 21:28:29 2018: Variables saved\n",
      "INFO:tensorflow:Sat Nov 17 21:28:40 2018: Epoch: 014 Step/Batch: 000000711 Step mean time: 1465ms \n",
      "Loss: 1.5824232 Training accuracy: 0.5625\n",
      "INFO:tensorflow:Sat Nov 17 21:28:50 2018: Epoch: 014 Step/Batch: 000000712 Step mean time: 1471ms \n",
      "Loss: 1.5201120 Training accuracy: 0.6875\n",
      "INFO:tensorflow:Sat Nov 17 21:29:01 2018: Epoch: 014 Step/Batch: 000000713 Step mean time: 1478ms \n",
      "Loss: 1.3993487 Training accuracy: 0.7500\n",
      "INFO:tensorflow:Sat Nov 17 21:29:12 2018: Epoch: 014 Step/Batch: 000000714 Step mean time: 1487ms \n",
      "Loss: 1.7226343 Training accuracy: 0.5625\n",
      "INFO:tensorflow:Sat Nov 17 21:29:22 2018: Epoch: 014 Step/Batch: 000000715 Step mean time: 1493ms \n",
      "Loss: 1.4650965 Training accuracy: 0.6875\n",
      "INFO:tensorflow:Sat Nov 17 21:29:35 2018: Elapsed time: 2207ms --- Loss: 2.7770848 Validation accuracy: 0.2400\n",
      "INFO:tensorflow:Sat Nov 17 21:29:45 2018: Epoch: 014 Step/Batch: 000000716 Step mean time: 1500ms \n",
      "Loss: 1.2842834 Training accuracy: 0.6875\n",
      "INFO:tensorflow:Sat Nov 17 21:29:55 2018: Epoch: 014 Step/Batch: 000000717 Step mean time: 1506ms \n",
      "Loss: 1.4710739 Training accuracy: 0.6250\n",
      "INFO:tensorflow:Sat Nov 17 21:30:00 2018: Epoch: 014 Step/Batch: 000000718 Step mean time: 1508ms \n",
      "Loss: 1.2808377 Training accuracy: 0.6250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Sat Nov 17 21:30:10 2018: Epoch: 015 Step/Batch: 000000719 Step mean time: 1515ms \n",
      "Loss: 1.0148653 Training accuracy: 0.8125\n",
      "INFO:tensorflow:Sat Nov 17 21:30:20 2018: Epoch: 015 Step/Batch: 000000720 Step mean time: 1522ms \n",
      "Loss: 1.6286139 Training accuracy: 0.5625\n",
      "INFO:tensorflow:Sat Nov 17 21:30:33 2018: Elapsed time: 2265ms --- Loss: 3.1113844 Validation accuracy: 0.2000\n",
      "INFO:tensorflow:Sat Nov 17 21:30:33 2018: Variables saved\n",
      "INFO:tensorflow:Sat Nov 17 21:30:43 2018: Epoch: 015 Step/Batch: 000000721 Step mean time: 1528ms \n",
      "Loss: 1.3900125 Training accuracy: 0.6250\n",
      "INFO:tensorflow:Sat Nov 17 21:30:53 2018: Epoch: 015 Step/Batch: 000000722 Step mean time: 1535ms \n",
      "Loss: 1.3904812 Training accuracy: 0.8125\n",
      "INFO:tensorflow:Sat Nov 17 21:31:03 2018: Epoch: 015 Step/Batch: 000000723 Step mean time: 1541ms \n",
      "Loss: 1.6206560 Training accuracy: 0.4375\n",
      "INFO:tensorflow:Sat Nov 17 21:31:13 2018: Epoch: 015 Step/Batch: 000000724 Step mean time: 1547ms \n",
      "Loss: 1.3186312 Training accuracy: 0.6250\n",
      "INFO:tensorflow:Sat Nov 17 21:31:24 2018: Epoch: 015 Step/Batch: 000000725 Step mean time: 1554ms \n",
      "Loss: 1.3864505 Training accuracy: 0.6875\n",
      "INFO:tensorflow:Sat Nov 17 21:31:38 2018: Elapsed time: 2330ms --- Loss: 3.5859528 Validation accuracy: 0.1600\n",
      "INFO:tensorflow:Sat Nov 17 21:31:48 2018: Epoch: 015 Step/Batch: 000000726 Step mean time: 1561ms \n",
      "Loss: 1.2511752 Training accuracy: 0.7500\n",
      "INFO:tensorflow:Sat Nov 17 21:31:59 2018: Epoch: 015 Step/Batch: 000000727 Step mean time: 1567ms \n",
      "Loss: 1.7678702 Training accuracy: 0.5625\n",
      "INFO:tensorflow:Sat Nov 17 21:32:09 2018: Epoch: 015 Step/Batch: 000000728 Step mean time: 1574ms \n",
      "Loss: 1.4551216 Training accuracy: 0.6875\n",
      "INFO:tensorflow:Sat Nov 17 21:32:20 2018: Epoch: 015 Step/Batch: 000000729 Step mean time: 1581ms \n",
      "Loss: 1.1208290 Training accuracy: 0.8750\n",
      "INFO:tensorflow:Sat Nov 17 21:32:30 2018: Epoch: 015 Step/Batch: 000000730 Step mean time: 1588ms \n",
      "Loss: 1.5786668 Training accuracy: 0.5625\n",
      "INFO:tensorflow:Sat Nov 17 21:32:43 2018: Elapsed time: 2395ms --- Loss: 3.0320187 Validation accuracy: 0.2400\n",
      "INFO:tensorflow:Sat Nov 17 21:32:43 2018: Variables saved\n",
      "INFO:tensorflow:Sat Nov 17 21:32:49 2018: Epoch: 015 Step/Batch: 000000731 Step mean time: 1590ms \n",
      "Loss: 1.1916040 Training accuracy: 0.7500\n",
      "INFO:tensorflow:Sat Nov 17 21:32:59 2018: Epoch: 016 Step/Batch: 000000732 Step mean time: 1596ms \n",
      "Loss: 1.1548846 Training accuracy: 0.8125\n",
      "INFO:tensorflow:Sat Nov 17 21:33:09 2018: Epoch: 016 Step/Batch: 000000733 Step mean time: 1603ms \n",
      "Loss: 1.7015953 Training accuracy: 0.5625\n",
      "INFO:tensorflow:Sat Nov 17 21:33:20 2018: Epoch: 016 Step/Batch: 000000734 Step mean time: 1609ms \n",
      "Loss: 1.3662285 Training accuracy: 0.6875\n",
      "INFO:tensorflow:Sat Nov 17 21:33:30 2018: Epoch: 016 Step/Batch: 000000735 Step mean time: 1616ms \n",
      "Loss: 1.2477415 Training accuracy: 0.7500\n",
      "INFO:tensorflow:Sat Nov 17 21:33:43 2018: Elapsed time: 2455ms --- Loss: 3.1955760 Validation accuracy: 0.1800\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(CKPT_PATH):\n",
    "    os.makedirs(CKPT_PATH)\n",
    "train(alexnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:** tfe.Network is deprecated and will be removed in a future version.\n",
      "\n",
      "Please inherit from `tf.keras.Model`, and see its documentation for details. `tf.keras.Model` should be a drop-in replacement for `tfe.Network` in most cases, but note that `track_layer` is no longer necessary or supported. Instead, `Layer` instances are tracked on attribute assignment (see the section of `tf.keras.Model`'s documentation on subclassing). Since the output of `track_layer` is often assigned to an attribute anyway, most code can be ported by simply removing the `track_layer` calls.\n",
      "\n",
      "`tf.keras.Model` works with all TensorFlow `Layer` instances, including those from `tf.layers`, but switching to the `tf.keras.layers` versions along with the migration to `tf.keras.Model` is recommended, since it will preserve variable names. Feel free to import it with an alias to avoid excess typing :).\n"
     ]
    }
   ],
   "source": [
    "newnet = AlexNet(training = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Deprecation Warning: create_summary_file_writer was renamed to create_file_writer\n",
      "INFO:tensorflow:Sat Nov 17 22:31:45 2018: Epoch: 000 Step/Batch: 000000012 Step mean time: 0285ms \n",
      "Loss: 2.8949721 Training accuracy: 0.3750\n",
      "INFO:tensorflow:Sat Nov 17 22:31:50 2018: Epoch: 001 Step/Batch: 000000013 Step mean time: 0495ms \n",
      "Loss: 2.7392097 Training accuracy: 0.3750\n",
      "INFO:tensorflow:Sat Nov 17 22:31:55 2018: Epoch: 002 Step/Batch: 000000014 Step mean time: 0675ms \n",
      "Loss: 2.5607433 Training accuracy: 0.3750\n",
      "INFO:tensorflow:Sat Nov 17 22:32:01 2018: Epoch: 003 Step/Batch: 000000015 Step mean time: 0858ms \n",
      "Loss: 2.3864205 Training accuracy: 0.3750\n",
      "INFO:tensorflow:Sat Nov 17 22:32:06 2018: Epoch: 004 Step/Batch: 000000016 Step mean time: 1002ms \n",
      "Loss: 2.2808108 Training accuracy: 0.3750\n",
      "INFO:tensorflow:Sat Nov 17 22:32:12 2018: Epoch: 005 Step/Batch: 000000017 Step mean time: 1148ms \n",
      "Loss: 2.1603651 Training accuracy: 0.3750\n",
      "INFO:tensorflow:Sat Nov 17 22:32:17 2018: Epoch: 006 Step/Batch: 000000018 Step mean time: 1272ms \n",
      "Loss: 1.9806359 Training accuracy: 0.5000\n",
      "INFO:tensorflow:Sat Nov 17 22:32:22 2018: Epoch: 007 Step/Batch: 000000019 Step mean time: 1370ms \n",
      "Loss: 1.8281553 Training accuracy: 0.5000\n",
      "INFO:tensorflow:Sat Nov 17 22:32:27 2018: Epoch: 008 Step/Batch: 000000020 Step mean time: 1456ms \n",
      "Loss: 1.7618362 Training accuracy: 0.6250\n",
      "INFO:tensorflow:Sat Nov 17 22:32:33 2018: Epoch: 009 Step/Batch: 000000021 Step mean time: 1554ms \n",
      "Loss: 1.6413622 Training accuracy: 0.8750\n",
      "INFO:tensorflow:Sat Nov 17 22:32:39 2018: Epoch: 010 Step/Batch: 000000022 Step mean time: 1638ms \n",
      "Loss: 1.5695767 Training accuracy: 0.7500\n",
      "INFO:tensorflow:Sat Nov 17 22:32:44 2018: Epoch: 011 Step/Batch: 000000023 Step mean time: 1708ms \n",
      "Loss: 1.4873630 Training accuracy: 0.6250\n",
      "INFO:tensorflow:Sat Nov 17 22:32:49 2018: Epoch: 012 Step/Batch: 000000024 Step mean time: 1768ms \n",
      "Loss: 1.4027081 Training accuracy: 0.7500\n",
      "INFO:tensorflow:Sat Nov 17 22:32:55 2018: Epoch: 013 Step/Batch: 000000025 Step mean time: 1835ms \n",
      "Loss: 1.2866170 Training accuracy: 0.7500\n",
      "INFO:tensorflow:Sat Nov 17 22:33:00 2018: Epoch: 014 Step/Batch: 000000026 Step mean time: 1887ms \n",
      "Loss: 1.2219632 Training accuracy: 0.8750\n",
      "INFO:tensorflow:Sat Nov 17 22:33:06 2018: Epoch: 015 Step/Batch: 000000027 Step mean time: 1939ms \n",
      "Loss: 1.1010902 Training accuracy: 0.8750\n",
      "INFO:tensorflow:Sat Nov 17 22:33:11 2018: Epoch: 016 Step/Batch: 000000028 Step mean time: 1989ms \n",
      "Loss: 1.0514405 Training accuracy: 0.8750\n",
      "INFO:tensorflow:Sat Nov 17 22:33:16 2018: Epoch: 017 Step/Batch: 000000029 Step mean time: 2026ms \n",
      "Loss: 0.9454465 Training accuracy: 1.0000\n",
      "INFO:tensorflow:Sat Nov 17 22:33:21 2018: Epoch: 018 Step/Batch: 000000030 Step mean time: 2065ms \n",
      "Loss: 0.8980878 Training accuracy: 0.8750\n",
      "INFO:tensorflow:Sat Nov 17 22:33:26 2018: Epoch: 019 Step/Batch: 000000031 Step mean time: 2101ms \n",
      "Loss: 0.8262911 Training accuracy: 1.0000\n",
      "INFO:tensorflow:Sat Nov 17 22:33:31 2018: Epoch: 020 Step/Batch: 000000032 Step mean time: 2133ms \n",
      "Loss: 0.7841054 Training accuracy: 1.0000\n",
      "INFO:tensorflow:Sat Nov 17 22:33:36 2018: Epoch: 021 Step/Batch: 000000033 Step mean time: 2163ms \n",
      "Loss: 0.7401198 Training accuracy: 1.0000\n",
      "INFO:tensorflow:Sat Nov 17 22:33:41 2018: Epoch: 022 Step/Batch: 000000034 Step mean time: 2189ms \n",
      "Loss: 0.7061805 Training accuracy: 1.0000\n",
      "INFO:tensorflow:Sat Nov 17 22:33:46 2018: Epoch: 023 Step/Batch: 000000035 Step mean time: 2215ms \n",
      "Loss: 0.6833094 Training accuracy: 1.0000\n",
      "INFO:tensorflow:Sat Nov 17 22:33:51 2018: Epoch: 024 Step/Batch: 000000036 Step mean time: 2237ms \n",
      "Loss: 0.6654106 Training accuracy: 1.0000\n",
      "INFO:tensorflow:Sat Nov 17 22:33:56 2018: Epoch: 025 Step/Batch: 000000037 Step mean time: 2260ms \n",
      "Loss: 0.6569425 Training accuracy: 1.0000\n",
      "INFO:tensorflow:Sat Nov 17 22:34:01 2018: Epoch: 026 Step/Batch: 000000038 Step mean time: 2281ms \n",
      "Loss: 0.6442602 Training accuracy: 1.0000\n",
      "INFO:tensorflow:Sat Nov 17 22:34:06 2018: Epoch: 027 Step/Batch: 000000039 Step mean time: 2302ms \n",
      "Loss: 0.6414902 Training accuracy: 1.0000\n",
      "INFO:tensorflow:Sat Nov 17 22:34:12 2018: Epoch: 028 Step/Batch: 000000040 Step mean time: 2331ms \n",
      "Loss: 0.6295123 Training accuracy: 1.0000\n",
      "INFO:tensorflow:Sat Nov 17 22:34:18 2018: Epoch: 029 Step/Batch: 000000041 Step mean time: 2362ms \n",
      "Loss: 0.6252962 Training accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "train(newnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (_, (test_images, test_labels)) in enumerate(test_dset):\n",
    "    l = loss(alexnet, 'val', test_images, test_labels)\n",
    "    a = accuracy(alexnet, 'val', test_images, test_labels).numpy()\n",
    "log_msg('Final Test Loss: {:.7f} Test accuracy: {:.4f}'.format(l, a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10 = tf.keras.datasets.cifar10.load_data()\n",
    "(X_train, y_train), _ = cifar10\n",
    "X_train = np.asarray(X_train, dtype=np.float32)\n",
    "y_train = np.asarray(y_train, dtype=np.int32).flatten()\n",
    "    \n",
    "mean_pixel = X_train.mean(axis=(0, 1, 2), keepdims=True)\n",
    "std_pixel = X_train.std(axis=(0, 1, 2), keepdims=True)\n",
    "X_train_normalised = (X_train - mean_pixel) / std_pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "train_examples_with_label = {}\n",
    "for i in range(10):\n",
    "    train_examples_with_label[i] = np.array([index for index, value in enumerate(y_train) if value == i])\n",
    "train_labels = []\n",
    "for i in range(10):\n",
    "    train_labels = train_labels + random.sample(list(train_examples_with_label[i]), int(1))\n",
    "random.shuffle(train_labels)\n",
    "X_train = X_train[train_labels]\n",
    "y_train = y_train[train_labels]\n",
    "X_train_normalised = X_train_normalised[train_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = './images'\n",
    "if not os.path.exists(image_path):\n",
    "    os.makedirs(image_path)\n",
    "def resize_datasets(X):\n",
    "    X_new = []\n",
    "    for i in range(X.shape[0]):\n",
    "        img = scipy.ndimage.interpolation.zoom(X[i], (8.0, 8.0, 1.0))\n",
    "        X_new.append(img)\n",
    "    X_new = np.asarray(X_new, dtype=np.float32)\n",
    "    return X_new.reshape([X.shape[0], 256, 256, 3])\n",
    "X_train_resized = resize_datasets(X_train)\n",
    "X_train_normalised_resized = resize_datasets(X_train_normalised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dset = Dataset(X_train_normalised_resized, y_train, batch_size=10, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newnet = AlexNet(training = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Deprecation Warning: create_summary_file_writer was renamed to create_file_writer\n",
      "INFO:tensorflow:Sat Nov 17 23:46:09 2018: Epoch: 000 Step/Batch: 000000132 Step mean time: 0011ms \n",
      "Loss: 1.5615523 Training accuracy: 0.7000\n",
      "INFO:tensorflow:Sat Nov 17 23:46:11 2018: Epoch: 001 Step/Batch: 000000133 Step mean time: 0022ms \n",
      "Loss: 0.5384739 Training accuracy: 1.0000\n",
      "INFO:tensorflow:Sat Nov 17 23:46:13 2018: Epoch: 002 Step/Batch: 000000134 Step mean time: 0032ms \n",
      "Loss: 1.5018649 Training accuracy: 0.8000\n",
      "INFO:tensorflow:Sat Nov 17 23:46:16 2018: Epoch: 003 Step/Batch: 000000135 Step mean time: 0042ms \n",
      "Loss: 0.9185445 Training accuracy: 0.9000\n",
      "INFO:tensorflow:Sat Nov 17 23:46:18 2018: Epoch: 004 Step/Batch: 000000136 Step mean time: 0053ms \n",
      "Loss: 0.6333767 Training accuracy: 0.9000\n",
      "INFO:tensorflow:Sat Nov 17 23:46:20 2018: Epoch: 005 Step/Batch: 000000137 Step mean time: 0062ms \n",
      "Loss: 0.5300307 Training accuracy: 1.0000\n",
      "INFO:tensorflow:Sat Nov 17 23:46:22 2018: Epoch: 006 Step/Batch: 000000138 Step mean time: 0072ms \n",
      "Loss: 0.5266472 Training accuracy: 1.0000\n",
      "INFO:tensorflow:Sat Nov 17 23:46:25 2018: Epoch: 007 Step/Batch: 000000139 Step mean time: 0082ms \n",
      "Loss: 0.5288626 Training accuracy: 1.0000\n",
      "INFO:tensorflow:Sat Nov 17 23:46:27 2018: Epoch: 008 Step/Batch: 000000140 Step mean time: 0092ms \n",
      "Loss: 0.5603593 Training accuracy: 1.0000\n",
      "INFO:tensorflow:Sat Nov 17 23:46:29 2018: Epoch: 009 Step/Batch: 000000141 Step mean time: 0101ms \n",
      "Loss: 0.5717998 Training accuracy: 1.0000\n",
      "INFO:tensorflow:Sat Nov 17 23:46:32 2018: Epoch: 010 Step/Batch: 000000142 Step mean time: 0111ms \n",
      "Loss: 0.5533749 Training accuracy: 1.0000\n",
      "INFO:tensorflow:Sat Nov 17 23:46:34 2018: Epoch: 011 Step/Batch: 000000143 Step mean time: 0120ms \n",
      "Loss: 0.5288216 Training accuracy: 1.0000\n",
      "INFO:tensorflow:Sat Nov 17 23:46:36 2018: Epoch: 012 Step/Batch: 000000144 Step mean time: 0129ms \n",
      "Loss: 0.5177788 Training accuracy: 1.0000\n",
      "INFO:tensorflow:Sat Nov 17 23:46:38 2018: Epoch: 013 Step/Batch: 000000145 Step mean time: 0139ms \n",
      "Loss: 0.5147122 Training accuracy: 1.0000\n",
      "INFO:tensorflow:Sat Nov 17 23:46:41 2018: Epoch: 014 Step/Batch: 000000146 Step mean time: 0148ms \n",
      "Loss: 0.5137888 Training accuracy: 1.0000\n",
      "INFO:tensorflow:Sat Nov 17 23:46:43 2018: Epoch: 015 Step/Batch: 000000147 Step mean time: 0157ms \n",
      "Loss: 0.5117458 Training accuracy: 1.0000\n",
      "INFO:tensorflow:Sat Nov 17 23:46:45 2018: Epoch: 016 Step/Batch: 000000148 Step mean time: 0165ms \n",
      "Loss: 0.5082467 Training accuracy: 1.0000\n",
      "INFO:tensorflow:Sat Nov 17 23:46:48 2018: Epoch: 017 Step/Batch: 000000149 Step mean time: 0175ms \n",
      "Loss: 0.5046098 Training accuracy: 1.0000\n",
      "INFO:tensorflow:Sat Nov 17 23:46:51 2018: Epoch: 018 Step/Batch: 000000150 Step mean time: 0185ms \n",
      "Loss: 0.5014412 Training accuracy: 1.0000\n",
      "INFO:tensorflow:Sat Nov 17 23:46:53 2018: Epoch: 019 Step/Batch: 000000151 Step mean time: 0194ms \n",
      "Loss: 0.4987217 Training accuracy: 1.0000\n",
      "INFO:tensorflow:Sat Nov 17 23:46:55 2018: Epoch: 020 Step/Batch: 000000152 Step mean time: 0201ms \n",
      "Loss: 0.4963304 Training accuracy: 1.0000\n",
      "INFO:tensorflow:Sat Nov 17 23:46:57 2018: Epoch: 021 Step/Batch: 000000153 Step mean time: 0209ms \n",
      "Loss: 0.4941498 Training accuracy: 1.0000\n",
      "INFO:tensorflow:Sat Nov 17 23:46:59 2018: Epoch: 022 Step/Batch: 000000154 Step mean time: 0217ms \n",
      "Loss: 0.4921117 Training accuracy: 1.0000\n",
      "INFO:tensorflow:Sat Nov 17 23:47:02 2018: Epoch: 023 Step/Batch: 000000155 Step mean time: 0224ms \n",
      "Loss: 0.4901639 Training accuracy: 1.0000\n",
      "INFO:tensorflow:Sat Nov 17 23:47:04 2018: Epoch: 024 Step/Batch: 000000156 Step mean time: 0232ms \n",
      "Loss: 0.4882706 Training accuracy: 1.0000\n",
      "INFO:tensorflow:Sat Nov 17 23:47:06 2018: Epoch: 025 Step/Batch: 000000157 Step mean time: 0239ms \n",
      "Loss: 0.4864134 Training accuracy: 1.0000\n",
      "INFO:tensorflow:Sat Nov 17 23:47:08 2018: Epoch: 026 Step/Batch: 000000158 Step mean time: 0246ms \n",
      "Loss: 0.4845794 Training accuracy: 1.0000\n",
      "INFO:tensorflow:Sat Nov 17 23:47:10 2018: Epoch: 027 Step/Batch: 000000159 Step mean time: 0253ms \n",
      "Loss: 0.4827582 Training accuracy: 1.0000\n",
      "INFO:tensorflow:Sat Nov 17 23:47:12 2018: Epoch: 028 Step/Batch: 000000160 Step mean time: 0260ms \n",
      "Loss: 0.4809425 Training accuracy: 1.0000\n",
      "INFO:tensorflow:Sat Nov 17 23:47:15 2018: Epoch: 029 Step/Batch: 000000161 Step mean time: 0267ms \n",
      "Loss: 0.4791375 Training accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "train(newnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = './images'\n",
    "if not os.path.exists(image_path):\n",
    "    os.makedirs(image_path)\n",
    "for i in range(X_train_resized.shape[0]):\n",
    "    image_path_local = image_path + '/' + str(i)\n",
    "    if not os.path.exists(image_path_local):\n",
    "        os.makedirs(image_path_local)\n",
    "    curr_input_image = X_train_resized[i, :, :, :]\n",
    "    curr_input_image = tf.reshape(curr_input_image/255.0, (256, 256, 3))\n",
    "    cv2.imwrite(image_path_local + '/input_image_' + str(i) + '.png', curr_input_image.numpy()*255.0)\n",
    "    _,attention1, attention2 = newnet(tf.reshape(X_train_normalised_resized[i, :, :, :], (1, 256, 256, 3)))\n",
    "    attention1 = np.array(np.repeat(attention1.numpy().reshape(15,15,1), 3, axis = 2))\n",
    "    attention2 = np.array(np.repeat(attention2.numpy().reshape(15,15,1), 3, axis = 2))\n",
    "    attention1 = cv2.normalize(attention1, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "    attention2 = cv2.normalize(attention2, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "    cv2.imwrite(image_path_local + '/attention1_' + str(i) + '.png', attention1)\n",
    "    cv2.imwrite(image_path_local + '/attention2_' + str(i) + '.png', attention2)\n",
    "    heatmap1 = cv2.resize(cv2.imread(image_path_local + '/attention1_' + str(i) + '.png'), (256,256))\n",
    "    heatmap2 = cv2.resize(cv2.imread(image_path_local + '/attention2_' + str(i) + '.png'), (256,256))\n",
    "    image = cv2.resize(cv2.imread(image_path_local + '/input_image_' + str(i) + '.png'), (256,256))\n",
    "    heatmap1 = cv2.applyColorMap(heatmap1, cv2.COLORMAP_JET)\n",
    "    heatmap2 = cv2.applyColorMap(heatmap2, cv2.COLORMAP_JET)\n",
    "    overlay1 = cv2.addWeighted(heatmap1, 0.6, image, 0.4, 0)\n",
    "    overlay2 = cv2.addWeighted(heatmap2, 0.6, image, 0.4, 0)\n",
    "    cv2.imwrite(image_path_local + '/overlay_attention1_' + str(i) + '.png', overlay1)\n",
    "    cv2.imwrite(image_path_local + '/overlay_attention2_' + str(i) + '.png', overlay2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
